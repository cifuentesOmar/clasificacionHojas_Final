{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e46d7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Importación de librerias\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df5871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import deserialize, serialize\n",
    "from tensorflow.python.keras.saving import saving_utils\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import os \n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001643c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Cargar set de Imágenes\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea92e02-ba49-4854-bf14-3f243c98c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de las imágenes\n",
    "DEFAULT_IMAGE_SIZE = tuple((256, 256))\n",
    "\n",
    "# Número de imagenes a utilizar\n",
    "N_IMAGES = 281\n",
    "\n",
    "# Ruta de carpeta de imágenes\n",
    "root_dir = 'Fotos'\n",
    "\n",
    "#train_dir = os.path.join(root_dir, 'train')\n",
    "#val_dir = os.path.join(root_dir, 'val')\n",
    "\n",
    "#train_dir = 'Fotos'\n",
    "#val_dir = 'Fotos'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcf112-dc8e-447b-adf1-8abec9a3a306",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Convertir images en arreglos\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c249c8d-3154-4e9b-9128-6a7b266e039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e676b-fa4a-441a-814a-9a3efba8f544",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Procesamiento de imágenes\n",
    "-----\n",
    "1. Identifación de carpetas \n",
    "2. Identificación de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4906060-24b1-404d-af6f-c375badb62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, label_list = [], []\n",
    "\n",
    "try:\n",
    "    print(\"[INFO] Procesamiento de imágenes...\")\n",
    "    plant_disease_folder_list = listdir(root_dir)\n",
    "    \n",
    "    for plant_disease_folder in plant_disease_folder_list:\n",
    "        print(f\"[INFO] Identificación de carpetas {plant_disease_folder}...\")\n",
    "        \n",
    "        if(plant_disease_folder != \".DS_Store\"):\n",
    "            plant_disease_image_list = listdir(f\"{root_dir}/{plant_disease_folder}/\")\n",
    "            for image in plant_disease_image_list[:N_IMAGES]:\n",
    "                image_directory = f\"{root_dir}/{plant_disease_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpeg\")==True or image_directory.endswith(\".JPG\")==True:\n",
    "                    image_list.append(convert_image_to_array(image_directory))\n",
    "                    label_list.append(plant_disease_folder)\n",
    "\n",
    "    print(\"[INFO] Procesamiento de imagenes exitoso.\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")\n",
    "    \n",
    "# Transformación de las imágenes de entrenamiento, cargados en una matriz numpy\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n",
    "\n",
    "# Comprobar del número de imágenes cargadas para el entrenamiento\n",
    "image_len = len(image_list)\n",
    "print(f\"Cantidad de imágenes: {image_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be7fd1-8c31-4424-9b82-6049e1e47db6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Etiquetado\n",
    "-----\n",
    "1. Identifación de clases\n",
    "2. Binarización de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3fb2d-e86a-428e-a612-dec199fe554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "pickle.dump(label_binarizer,open('plant_disease_label_transform.pkl', 'wb'))\n",
    "\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "\n",
    "print(\"Número de clases de imágenes: \", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3bc5bb-d1d2-4aca-9c17-7ad868e49f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Tratamiento de datos\n",
    "-----\n",
    "1. El aumento de datos no fue necesario, esto debido a que se obtuvieron mejores resultados sin la necesidad de aumentar las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669225ab-c67c-42f2-9e98-5c236def056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "#                              height_shift_range=0.1, shear_range=0.2, \n",
    "#                              zoom_range=0.2, horizontal_flip=True, \n",
    "#                              fill_mode=\"nearest\")\n",
    "    \n",
    "#augment = ImageDataGenerator()\n",
    "\n",
    "# img_dir_path = \"Fotos/no_sana\"\n",
    "# save_dir_path = \"Fotos/train\"\n",
    "\n",
    "# train_generator = augment.flow_from_directory(\n",
    "#     img_dir_path, \n",
    "#     target_size=(128, 128), \n",
    "#     color_mode=\"rgb\", \n",
    "#     batch_size=20, \n",
    "#     save_to_dir=\"Respaldo\", \n",
    "#     class_mode=\"binary\", \n",
    "#     save_prefix=\"augmented\", \n",
    "#     save_format=\"png\")\n",
    "\n",
    "# for i in range(10):\n",
    "#     train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ffab8-3d00-44fa-b09d-c7c9fafeca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Dividir el conjunto de datos en datos de entrenamiento y datos de prueba...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b3096-ac42-4ba3-8b66-89bb32c71ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer parámetros para el modelo\n",
    "EPOCHS = 20\n",
    "STEPS = 100\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 16  # Cantidad de muestra por cada época\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "DEPTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6376af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. CREAR ARQUITECTURA\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb957b-4691-4827-a424-1f3c80389489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "chanDim = -1\n",
    "\n",
    "print(K.image_data_format())\n",
    "\n",
    "#if K.image_data_format() == \"channels_first\":\n",
    "#    inputShape = (DEPTH, HEIGHT, WIDTH)\n",
    "#    chanDim = 1\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# Comprobar arquitectura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ab70a-9385-4ff8-9cbf-ec9ce64024e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Entrenamiento del modelo\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23825815-5d7c-4b97-a23f-50c3978f1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "# Activar el optimizador\n",
    "opt = Adam(learning_rate=LR, decay=LR/EPOCHS)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), f1_metric])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"[INFO] Entrenando al modelo...\")\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "                    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5b32f-f3e9-47a3-bb8e-c23151807930",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9. Análisis de métricas de rendimiento\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5db38-9a02-422b-be42-9e46ed4d1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "prec = history.history['precision']\n",
    "val_prec = history.history['val_precision']\n",
    "\n",
    "recall_1 = history.history['recall']\n",
    "val_recall = history.history['val_recall']\n",
    "\n",
    "f1 = history.history['f1_metric']\n",
    "val_f1 = history.history['val_f1_metric']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Pérdida de datos de entrenamiento y datos de prueba\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Accuracy de los datos de entrenamiento y datos de prueba\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Precisión de los datos de entrenamiento y datos de prueba\n",
    "plt.plot(epochs, prec, 'b', label='Training precision')\n",
    "plt.plot(epochs, val_prec, 'r', label='Validation precision')\n",
    "plt.title('Training and Validation precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Recall de los datos de entrenamiento y datos de prueba\n",
    "plt.plot(epochs, recall_1, 'b', label='Training recall')\n",
    "plt.plot(epochs, val_recall, 'r', label='Validation recall')\n",
    "plt.title('Training and Validation recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# F1 de los datos de entrenamiento y datos de prueba\n",
    "plt.plot(epochs, f1, 'b', label='Training f1')\n",
    "plt.plot(epochs, val_f1, 'r', label='Validation f1')\n",
    "plt.title('Training and Validation f1')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d2c75-7396-4945-aa3d-cccd850af6ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 10. Evaluación de modelo\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a6c5f7-301e-4af7-8866-4ea29f7a78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Calcular la precisión del modelo....\")\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Exactitud de la prueba: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7ad17-9448-419a-8f88-7ebd6536cf5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 11. Guardar modelo\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ec1e8-81ee-40ad-bb01-c1ad87daf953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "print(\"[INFO] Guardar modelo...\")\n",
    "model.save('model.h5')\n",
    "#pickle.dump(model,open('cnn_model_a.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d845f759-63ae-4367-b8dc-8580308e2e6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 12. Realizar predicción\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b0e2a-9e52-4344-b276-e0d249749360",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5', compile=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy' ,tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "imgpath='Fotos_old/nosana.jpeg'\n",
    "\n",
    "imar = convert_image_to_array(imgpath)\n",
    "np_image_list = np.array([imar], dtype=np.float16) / 225.0\n",
    "\n",
    "predicted_classes = model.predict(np_image_list)\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    print(label_binarizer.classes_[img_tagged.tolist().index(max(img_tagged))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
